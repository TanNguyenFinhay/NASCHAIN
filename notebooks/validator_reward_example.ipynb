{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import bittensor as bt\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the behavior of the validator and how rewards are calculated.\n",
    "Additianlly it shows how miners are rated and scored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2024-04-09 23:51:14.813\u001b[0m | \u001b[1m      INFO      \u001b[0m | You are connecting to finney network with endpoint wss://entrypoint-finney.opentensor.ai:443.\n",
      "\u001b[34m2024-04-09 23:51:14.813\u001b[0m | \u001b[33m\u001b[1m    WARNING     \u001b[0m | We strongly encourage running a local subtensor node whenever possible. This increases decentralization and resilience of the network.\n",
      "\u001b[34m2024-04-09 23:51:14.813\u001b[0m | \u001b[33m\u001b[1m    WARNING     \u001b[0m | In a future release, local subtensor will become the default endpoint. To get ahead of this change, please run a local subtensor node and point to it.\n",
      "\u001b[34m2024-04-09 23:51:15.535\u001b[0m | \u001b[1m      INFO      \u001b[0m | Connected to finney network and wss://entrypoint-finney.opentensor.ai:443.\n"
     ]
    }
   ],
   "source": [
    "# NASChain NetUID\n",
    "naschain_uid = 31\n",
    "subtensor = bt.subtensor()\n",
    "metagraph = subtensor.metagraph(naschain_uid)\n",
    "genomaster_ip = '51.161.12.128'\n",
    "genomaster_port = 5000\n",
    "genomaster_valid_endpoint= '/handle_valid_request'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(df: pd.DataFrame , tolerance : int):\n",
    "    # Initialize the dictionary to store user scores and job counts\n",
    "    user_scores = defaultdict(lambda: {'points': 0, 'accepted_jobs': 0, 'rejected_jobs': 0})\n",
    "\n",
    "    # Process each job batch\n",
    "    for _, group in df.groupby('Genome_String'):\n",
    "        responses = group['Response'].tolist()\n",
    "        user_ids = group['Assigned_User'].tolist()\n",
    "\n",
    "        # Initialize agreement checks\n",
    "        agreements = [False] * len(user_ids)  # Default all to False\n",
    "\n",
    "        # Check pairwise agreement within tolerance for the first element and exact match for others\n",
    "        for i in range(len(responses)):\n",
    "            for j in range(i + 1, len(responses)):\n",
    "                # Check agreement between i and j\n",
    "                agree_first = abs(responses[i][0] - responses[j][0]) <= tolerance\n",
    "                agree_second = responses[i][1] == responses[j][1]\n",
    "                agree_third = responses[i][2] == responses[j][2]\n",
    "\n",
    "                # Update agreement status\n",
    "                if agree_first and agree_second and agree_third:\n",
    "                    agreements[i] = True\n",
    "                    agreements[j] = True\n",
    "\n",
    "        # Update scores based on agreement\n",
    "        for i, user_id in enumerate(user_ids):\n",
    "            if agreements[i]:\n",
    "                user_scores[user_id]['points'] += 1\n",
    "                user_scores[user_id]['accepted_jobs'] += 1\n",
    "            else:\n",
    "                user_scores[user_id]['rejected_jobs'] += 1\n",
    "\n",
    "    # Normalize the points and prepare the lists\n",
    "    total_points = sum(user['points'] for user in user_scores.values())\n",
    "    normalized_scores_list = []\n",
    "    user_ids_list = []\n",
    "\n",
    "    # Fill the lists with normalized scores and user IDs\n",
    "    for user_id, score in user_scores.items():\n",
    "        normalized_score = score['points'] / total_points if total_points > 0 else 0\n",
    "        normalized_scores_list.append(normalized_score)\n",
    "        user_ids_list.append(user_id)\n",
    "\n",
    "    \n",
    "    \n",
    "    all_users_in_metagraoh = list(range(int(metagraph.n)))\n",
    "    all_scores_tensor = torch.zeros(int(metagraph.n))\n",
    "    # Scatter the scores to the corresponding user IDs\n",
    "    all_scores_tensor[user_ids_list] = torch.tensor(normalized_scores_list)\n",
    "    return all_scores_tensor, all_users_in_metagraoh, user_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to GenoMaster to request all the jobs that\n",
    "# have been completed in the current Genetic Algorithm population.\n",
    "try:\n",
    "        # Construct the full URL\n",
    "        url = genomaster_ip + ':' + genomaster_port + '/handle_valid_request'\n",
    "        response = requests.get(url)  # This is a synchronous call, consider using an async library if needed\n",
    "        # Check the status code of the response\n",
    "        if response.status_code == 200:\n",
    "            bt.logging.info(\"✅ Validation request successful.\")\n",
    "            # Convert the JSON response to a pandas DataFrame\n",
    "            response_data = response.json()\n",
    "            df = pd.DataFrame(response_data)\n",
    "            # check to seee if there is new batch of data for validation is ready in genomaster \n",
    "            if self.valid_data_length != df.shape[0]:\n",
    "                bt.logging.info(\"✅ New batch arrived.. Updating Weights...\")\n",
    "                rewards, uids, msgs = get_rewards(self, query=self.step, responses_df=df)\n",
    "                self.update_scores(rewards, uids)\n",
    "                self.valid_data_length = df.shape[0]\n",
    "        elif response.status_code == 503:\n",
    "            bt.logging.warning(\"⏳ GenoMaster is currently busy, connections will be accepted soon.\")\n",
    "\n",
    "        else:\n",
    "            # bt.logging.error(\"❌ Validation request failed.\")\n",
    "            # bt.logging.error(\"❌ Status code:\", response.status_code)\n",
    "            bt.logging.warning(\"⏳ Validation request not complete. Message:\", response.json().get('message'))\n",
    "\n",
    "except Exception as e:\n",
    "        bt.logging.error(f\"❌ An error occurred: {e}\")\n",
    "        # Optionally, print the traceback if you need more details\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bittensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60050d296a7c7bf3d3a9a3faa6bc7a0dd371cb2fa748389cf16a6d13b60865ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
